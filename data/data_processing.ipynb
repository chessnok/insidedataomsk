{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch torchvision rasterio numpy matplotlib"],"metadata":{"id":"E_V5M7Q9gHyS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Используемые библиотеки"],"metadata":{"id":"7gZB6yQmhSM6"}},{"cell_type":"code","source":["import os\n","from PIL import Image, ImageFont, ImageDraw\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","import tifffile\n","import os\n","import zipfile\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import csv\n","import rasterio\n","import math\n","from sklearn.metrics import matthews_corrcoef\n","from tqdm import tqdm"],"metadata":{"id":"Iw64qfkUg920"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Предобработка"],"metadata":{"id":"eyxOZt6xfi0q"}},{"cell_type":"markdown","source":["#Изменение tiff файлов для проверки гипотез:"],"metadata":{"id":"88i7ObGbjP9f"}},{"cell_type":"markdown","source":["Изменяем tiff в jpg"],"metadata":{"id":"seRT0ob0vr1o"}},{"cell_type":"code","source":["# Достаем из tiff первые 3 потока для изменения tiff в jpg\n","for i in range(21):\n","    folder_name = i\n","    folder_name_str = f'merged/{folder_name:02}.tiff'\n","    with tifffile.TiffFile(folder_name_str) as tif:\n","        image_array = tif.asarray()\n","\n","    r = image_array[:, :, 0]\n","    g = image_array[:, :, 1]\n","    b = image_array[:, :, 2]\n","\n","    rgb_image = np.stack([r, g, b], axis=-1)\n","    # Сохраняем jpg в папку с изображениями\n","    rgb_image = rgb_image - np.min(rgb_image)\n","    rgb_image = rgb_image / np.max(rgb_image)\n","    rgb_image = (rgb_image * 255).astype(np.uint8)\n","    image_pil = Image.fromarray(rgb_image)\n","    image_pil.save(f'./jpgs/{folder_name:02}.jpg')"],"metadata":{"id":"jRcYcYJMjOO3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Отделяем маски от tiff"],"metadata":{"id":"PgddgYbrv4cj"}},{"cell_type":"code","source":["# Достаем из tiff маску\n","for i in range(21):\n","    folder_name_str = f'merged/{i:02}.tiff'\n","    with tifffile.TiffFile(folder_name_str) as tif:\n","        image_array = tif.asarray()\n","\n","    mask = image_array[:, :, 4]\n","    mask = mask - np.min(mask)\n","    mask = mask / np.max(mask)\n","    mask = (mask * 255).astype(np.uint8)\n","\n","    # Сохранение маски как черно-белого изображения\n","    mask_pil = Image.fromarray(mask, mode='L')\n","    mask_pil.save(f'masks/{i:02}.jpg')\n"],"metadata":{"id":"yorxs_bjvm0e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Создание отдельной папки для tiff файлов"],"metadata":{"id":"PhlmE6W7vcND"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Папка, где находятся все исходные папки\n","source_dir = 'minprirody_train/train'\n","\n","# Папка, куда будут перемещены и переименованы файлы\n","destination_dir = 'merged'\n","\n","# Создаем папку назначения, если она не существует\n","if not os.path.exists(destination_dir):\n","    os.makedirs(destination_dir)\n","\n","# Проходим по папкам от 00 до 20\n","for folder_name in range(21):\n","    folder_name_str = f'{folder_name:02}'  # Преобразуем число в строку с двумя цифрами\n","    folder_path = os.path.join(source_dir, folder_name_str)\n","\n","    # Проверяем, существует ли папка\n","    if os.path.isdir(folder_path):\n","        # Предполагаем, что в каждой папке только один файл .tiff\n","        files = [f for f in os.listdir(folder_path) if f.endswith('.tiff')]\n","\n","        if files:\n","            # Переименовываем и перемещаем файл\n","            file_path = os.path.join(folder_path, files[0])\n","            new_file_name = f'{folder_name_str}.tiff'\n","            new_file_path = os.path.join(destination_dir, new_file_name)\n","            shutil.copy(file_path, new_file_path)  # Копируем файл в новую папку\n","        else:\n","            print(f'No .tiff files found in folder {folder_path}')\n","\n","print(\"Files have been successfully merged.\")"],"metadata":{"id":"xms6lyQvjOKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Формируем методату из tiff"],"metadata":{"id":"XFrrKz2mlWmS"}},{"cell_type":"code","source":["# Путь к папке с TIFF файлами\n","folder_path = 'merged'\n","\n","# Список для хранения данных\n","data = []\n","\n","# Проходим по всем файлам в папке merged\n","for file_name in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, file_name)\n","\n","    # Открываем каждый TIFF-файл с помощью rasterio\n","    with rasterio.open(file_path) as dataset:\n","        # Получаем BoundingBox\n","        bbox = dataset.bounds\n","        # Вычисляем ширину и высоту\n","        width, height = dataset.width, dataset.height\n","        # Получаем координаты верхнего левого угла\n","        top_left_lng, top_left_lat = bbox.left, bbox.top\n","\n","        # Добавляем информацию в список\n","        data.append([file_name, width, height, top_left_lng, top_left_lat])\n","\n","# Создаем DataFrame с использованием pandas\n","df = pd.DataFrame(data,\n","                  columns=['file_name', 'width', 'height', 'top_left_lng',\n","                           'top_left_lat'])\n","\n","# Сохраняем данные в CSV файл\n","df.to_csv('metadata.csv', index=False)"],"metadata":{"id":"9_lkKbTMjOER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Аугментация данных при помощи \"нарезки\" масок исходных tiff на менее масштаные снимки"],"metadata":{"id":"WUmXs_EQnNfR"}},{"cell_type":"code","source":["# Функция для разрезания изображения на куски\n","def split_image(image, chunk_size):\n","    img_width, img_height = image.size\n","    chunks = []\n","    for i in range(0, img_width, chunk_size):\n","        for j in range(0, img_height, chunk_size):\n","            box = (i, j, i + chunk_size, j + chunk_size)\n","            chunk = image.crop(box)\n","            chunks.append(chunk)\n","    return chunks\n","\n","# Папки с исходными данными и новые папки\n","input_images_folder = 'jpgs'\n","input_masks_folder = 'masks'\n","output_folder = 'new_data'\n","output_images_folder = os.path.join(output_folder, 'images')\n","output_masks_folder = os.path.join(output_folder, 'masks')\n","\n","# Создание новых папок\n","os.makedirs(output_images_folder, exist_ok=True)\n","os.makedirs(output_masks_folder, exist_ok=True)\n","\n","# Разрезаем изображения и маски\n","def process_folder(input_folder, output_folder, chunk_size):\n","    for filename in os.listdir(input_folder):\n","        if filename.endswith('.jpg') or filename.endswith('.png'):\n","            file_path = os.path.join(input_folder, filename)\n","            image = Image.open(file_path)\n","            chunks = split_image(image, chunk_size)\n","\n","            for idx, chunk in enumerate(chunks):\n","                chunk_filename = f\"{filename[:-4]}_{idx}.jpg\"\n","                chunk_path = os.path.join(output_folder, chunk_filename)\n","                chunk.save(chunk_path)\n","\n","# Обработка изображений и масок\n","process_folder(input_images_folder, output_images_folder, 256)\n","process_folder(input_masks_folder, output_masks_folder, 256)\n","\n","print(\"Разрезка изображений и масок завершена.\")"],"metadata":{"id":"xbXHcLxSnNEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Использование U-Net для сигментации изображения и создания масок"],"metadata":{"id":"qc9YoA0_m69j"}},{"cell_type":"code","source":["# Класс U-NET\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        self.encoder1 = self.conv_block(in_channels, 64)\n","        self.encoder2 = self.conv_block(64, 128)\n","        self.encoder3 = self.conv_block(128, 256)\n","        self.encoder4 = self.conv_block(256, 512)\n","\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        self.middle = self.conv_block(512, 1024)\n","\n","        self.upconv4 = self.upconv_block(1024, 512)\n","        self.decoder4 = self.conv_block(1024, 512)\n","        self.upconv3 = self.upconv_block(512, 256)\n","        self.decoder3 = self.conv_block(512, 256)\n","        self.upconv2 = self.upconv_block(256, 128)\n","        self.decoder2 = self.conv_block(256, 128)\n","        self.upconv1 = self.upconv_block(128, 64)\n","        self.decoder1 = self.conv_block(128, 64)\n","\n","        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def conv_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def upconv_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        # Encoder\n","        enc1 = self.encoder1(x)\n","        enc2 = self.pool(enc1)\n","        enc2 = self.encoder2(enc2)\n","        enc3 = self.pool(enc2)\n","        enc3 = self.encoder3(enc3)\n","        enc4 = self.pool(enc3)\n","        enc4 = self.encoder4(enc4)\n","\n","        # Middle\n","        middle = self.pool(enc4)\n","        middle = self.middle(middle)\n","\n","        # Decoder\n","        up4 = self.upconv4(middle)\n","        cat4 = torch.cat([up4, enc4], dim=1)\n","        dec4 = self.decoder4(cat4)\n","\n","        up3 = self.upconv3(dec4)\n","        cat3 = torch.cat([up3, enc3], dim=1)\n","        dec3 = self.decoder3(cat3)\n","\n","        up2 = self.upconv2(dec3)\n","        cat2 = torch.cat([up2, enc2], dim=1)\n","        dec2 = self.decoder2(cat2)\n","\n","        up1 = self.upconv1(dec2)\n","        cat1 = torch.cat([up1, enc1], dim=1)\n","        dec1 = self.decoder1(cat1)\n","        print(dec1.shape)\n","\n","        out = self.final_conv(dec1)\n","        return out"],"metadata":{"id":"PbQnv-7tjN7m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["U-Net доказал свою эффективность во многих сферах на всевозможных соревнованиях где требовалась сигментация данныых и создание масок. Именно по этой причине мы решили реализовать данную модель"],"metadata":{"id":"qNIha4uTnxtq"}},{"cell_type":"markdown","source":["Предобработка input данных для U-Net"],"metadata":{"id":"sdwWgiTvon5g"}},{"cell_type":"code","source":["# Класс для сегментации датасета\n","class SegmentationDataset(Dataset):\n","    def __init__(self, images_dir, masks_dir, transform=None):\n","        self.images_dir = images_dir\n","        self.masks_dir = masks_dir\n","        self.transform = transform\n","\n","        self.image_filenames = sorted(os.listdir(images_dir))\n","        self.mask_filenames = sorted(os.listdir(masks_dir))\n","\n","        assert len(self.image_filenames) == len(self.mask_filenames),\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.images_dir, self.image_filenames[idx])\n","        mask_name = os.path.join(self.masks_dir, self.mask_filenames[idx])\n","\n","        image = Image.open(img_name).convert('RGB')\n","        mask = Image.open(mask_name).convert('L')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","            mask = self.transform(mask)\n","\n","        # Преобразуем маску в бинарный формат и удаляем лишнюю размерность\n","        mask = torch.where(mask > 0, torch.tensor(1.0), torch.tensor(0.0))\n","        mask = mask.squeeze(0)  # Удаляем размерность каналов, если есть\n","\n","        return image, mask\n","\n","# Примеры трансформаций для предварительной обработки изображений\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])"],"metadata":{"id":"gBR9old4oKbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Создание датасета и выборок"],"metadata":{"id":"Sy0YAC18o8YN"}},{"cell_type":"code","source":["images_dir = '/content/pics'\n","masks_dir = '/content/masks'\n","\n","# Создаем экземпляр датасета и DataLoader\n","dataset = SegmentationDataset(images_dir, masks_dir, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"],"metadata":{"id":"9IzO9RbgocGP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Обучение U-Net на исходных данных"],"metadata":{"id":"X3cfCeU6pYhJ"}},{"cell_type":"code","source":["# Устанавливаем устройство для вычислений (GPU или CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Создаем экземпляр модели UNet\n","model = UNet(in_channels=3, out_channels=1).to(device)\n","\n","# Определяем функцию потерь и оптимизатор\n","criterion = nn.BCEWithLogitsLoss()  # Используем BCEWithLogitsLoss для бинарной классификации\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Определяем количество эпох\n","num_epochs = 100\n","\n","# Цикл обучения\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    # Перебираем данные из DataLoader\n","    for images, masks in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","        images, masks = images.to(device), masks.to(device)\n","\n","        # Обратный проход\n","        optimizer.zero_grad()\n","\n","        # Прямой проход\n","        outputs = model(images)\n","\n","        # Вычисляем потерю\n","        masks = masks.unsqueeze(1)  # Добавляем размерность к маске, чтобы она совпадала с размером выхода\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","\n","    epoch_loss = running_loss / len(dataset)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n","    if epoch % 10 == 0:\n","        torch.save(model.state_dict(), f'unet_model{epoch}.pth')\n","\n","# Сохраняем модель\n","torch.save(model.state_dict(), 'unet_model.pth')\n","print(\"Model saved to 'unet_model.pth'\")"],"metadata":{"id":"dn2zUOM2pY5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  После обучение можно констатировать, что U-Net при данном объеме данных не способен выдовать нужную точность при создании масок\n","\n","\n"],"metadata":{"id":"ecvUOFz7p6Qg"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"t3s81LycqvsC"}},{"cell_type":"markdown","source":["#После повторного анализа исходных данных, мы пришли к решению оперировать параметром ИК для создания масок"],"metadata":{"id":"g9UxvoMeq58x"}},{"cell_type":"markdown","source":["Констатные значения"],"metadata":{"id":"dr-qXOiEx-kh"}},{"cell_type":"code","source":["ML = 0.00025  # коэффициент масштабирования радиометрии\n","AL = 0.05  # коэффициент смещения радиометрии\n","K1 = 765.0  # калибровочная константа K1\n","K2 = 1275.0  # калибровочная константа K2\n","epsilon = 0.93  # излучательная способность\n","lambda_ir = 10.9 * 10 ** -6  # длина волны ИК канала (мкм)\n","rho = 1.438 * 10 ** -2"],"metadata":{"id":"JxSyl9Mix8uh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Подсчет метрики"],"metadata":{"id":"oIBOHCSIym_l"}},{"cell_type":"code","source":["# Подсчет коэфициета Метьюса\n","def calculate_mcc(true_mask, predicted_mask):\n","    return matthews_corrcoef(true_mask.flatten(), predicted_mask.flatten())\n","\n","# Скейлим MCC\n","def scale_mcc(mcc):\n","    return (mcc + 1) / 2"],"metadata":{"id":"AUMYYtiZymYM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Формируем датасет"],"metadata":{"id":"2TgQ-U8Kh_p4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9L9CY3QWfg98"},"outputs":[],"source":["# Сбор информации из .tiff файла\n","class TiffData:\n","    def __init__(self, file_path):\n","        with rasterio.open(file_path) as dataset:\n","            self.infrared_layer = dataset.read(4)\n","            self.green_layer = dataset.read(2)\n","            self.true_fire_mask = dataset.read(5)\n","            self.dataset = dataset"]},{"cell_type":"markdown","source":["Алгоритм подбора оптимальных параметров"],"metadata":{"id":"Pq9e30rzszMM"}},{"cell_type":"code","source":["# Функция для поиска лучших гиперпараметров\n","def find_best_borders(tiff_files, step=0.1, delta=0.05):\n","    best_mcc = -1\n","    best_green_border = None\n","    best_lst_border = None\n","\n","    # Загрузка всех данных в память\n","    tiff_data_list = [TiffData(file_path) for file_path in tiff_files]\n","\n","    # Перебор значений green_border и lst_border\n","    for green_border in tqdm(np.arange(0, 1 + step, step),\n","                             desc=\"Перебор значений green_border\"):\n","        for lst_border in tqdm(np.arange(0, 1 + step, step),\n","                               desc=\"Перебор значений lst_border\",\n","                               leave=False):\n","            total_mcc = 0\n","            count = 0\n","\n","            for tiff_data in tiff_data_list:\n","                # Считываем слои\n","                infrared_layer = tiff_data.infrared_layer\n","                green_layer = tiff_data.green_layer\n","                true_fire_mask = tiff_data.true_fire_mask\n","\n","                # Преобразуем DN в радиометрическое излучение\n","                radiance = ML * infrared_layer + AL\n","                brightness_temp = K2 / (np.log((K1 / radiance) + 1))\n","                lst = brightness_temp / (1 + (\n","                            lambda_ir * brightness_temp / rho) * np.log(\n","                    epsilon))\n","                lst_celsius = lst - 273.15\n","                lst_celsius_normalized = (\n","                                                     lst_celsius - lst_celsius.min()) / (\n","                                                     lst_celsius.max() - lst_celsius.min())\n","\n","                # Создаем маску на основе границ\n","                final_mask = create_mask(green_layer,\n","                                         lst_celsius_normalized,\n","                                         green_border, lst_border)\n","\n","                # Вычисляем коэффициент Метьюса\n","                mcc = calculate_mcc(true_fire_mask, final_mask)\n","                scaled_mcc = scale_mcc(mcc)  # Применяем масштабирование\n","                total_mcc += scaled_mcc\n","                count += 1\n","\n","            # Средний коэффициент Метьюса\n","            average_mcc = total_mcc / count\n","\n","            # Проверяем, является ли текущий результат лучшим\n","            if average_mcc > best_mcc:\n","                best_mcc = average_mcc\n","                best_green_border = green_border\n","                best_lst_border = lst_border\n","                print(\n","                    f\"Улучшение результата: Green Border = {best_green_border}, LST Border = {best_lst_border}, MCC = {best_mcc}\")\n","\n","    # Перебор значений с ±delta от найденных лучших границ\n","    for green_border in [best_green_border + delta, best_green_border,\n","                         best_green_border - delta]:\n","        for lst_border in [best_lst_border + delta, best_lst_border,\n","                           best_lst_border - delta]:\n","            total_mcc = 0\n","            count = 0\n","            for tiff_data in tiff_data_list:\n","                # Считываем слои\n","                infrared_layer = tiff_data.infrared_layer\n","                green_layer = tiff_data.green_layer\n","                true_fire_mask = tiff_data.true_fire_mask\n","\n","                # Преобразуем DN в радиометрическое излучение\n","                radiance = ML * infrared_layer + AL\n","                brightness_temp = K2 / (np.log((K1 / radiance) + 1))\n","                lst = brightness_temp / (1 + (\n","                            lambda_ir * brightness_temp / rho) * np.log(\n","                    epsilon))\n","                lst_celsius = lst - 273.15\n","                lst_celsius_normalized = (\n","                                                     lst_celsius - lst_celsius.min()) / (\n","                                                     lst_celsius.max() - lst_celsius.min())\n","\n","                # Создаем маску на основе границ\n","                final_mask = create_mask(green_layer,\n","                                         lst_celsius_normalized,\n","                                         green_border, lst_border)\n","\n","                # Вычисляем коэффициент Метьюса\n","                mcc = calculate_mcc(true_fire_mask, final_mask)\n","                scaled_mcc = scale_mcc(mcc)  # Применяем масштабирование\n","                total_mcc += scaled_mcc\n","                count += 1\n","\n","            # Средний коэффициент Метьюса\n","            average_mcc = total_mcc / count\n","\n","            # Проверяем, является ли текущий результат лучшим\n","            if average_mcc > best_mcc:\n","                best_mcc = average_mcc\n","                best_green_border = green_border\n","                best_lst_border = lst_border\n","                print(\n","                    f\"Улучшение результата после уточнения: Green Border = {best_green_border}, LST Border = {best_lst_border}, MCC = {best_mcc}\")\n","\n","    return best_green_border, best_lst_border, best_mcc"],"metadata":{"id":"T3zv4_8VrbVN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Output алгоритма по созданию масок"],"metadata":{"id":"w2zyclR-tT1Y"}},{"cell_type":"code","source":["\n","tiff_files = [f\"merged/{i:02d}.tiff\" for i in range(21)]\n","\n","# Поиск лучших границ\n","best_green_border, best_lst_border, best_mcc = find_best_borders(tiff_files)\n","\n","print(f\"Best Green Border: {best_green_border}\")\n","print(f\"Best LST Border: {best_lst_border}\")\n","print(f\"Best Matthews Correlation Coefficient: {best_mcc}\")"],"metadata":{"id":"-teowWNDtUM8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Имплементация алгоритма по генерации масок"],"metadata":{"id":"K6sH_d88mOdt"}},{"cell_type":"markdown","source":["Имплементация и использование предобученного UNet для определения процента изображения покрытого лесом"],"metadata":{"id":"vB3WQXv0mtG4"}},{"cell_type":"code","source":["# Предобученная Ю-нет для подсчета процента деревьев на изображении\n","class UNet:\n","    def __init__(self):\n","        self.model = smp.Unet(encoder_name='resnet34',\n","                              encoder_weights='imagenet',\n","                              classes=1)\n","        self.model.eval()\n","        # preprocess для обработки входного изображения\n","        self.preprocess = transforms.Compose([\n","            transforms.Resize((256, 256)),\n","            transforms.ToTensor()\n","        ])\n","\n","    def predict(self, image_pil):\n","        input_image = self.preprocess(image_pil).unsqueeze(0)\n","\n","        with torch.no_grad():\n","            output = self.model(input_image)\n","        # Подсчет доли деревьев на снимке\n","        mask = (output.squeeze().numpy() > 0.5).astype(np.uint8)\n","        total_pixels = mask.size\n","        object_pixels = np.sum(mask)\n","        percentage_objects = (object_pixels / total_pixels) * 100\n","\n","        return percentage_objects"],"metadata":{"id":"kcd8AZYOmXlm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Расчет fire_score исходя из данных"],"metadata":{"id":"EB2BsiYDnITc"}},{"cell_type":"code","source":["# Подсчет fire_score для формулы\n","def calculate_fire_score(percentage_trees, humidity,\n","                         wind_speed):\n","    risk = 0\n","    risk += 0.5 * ((100 - humidity) / 100)\n","    risk += 0.5 * (wind_speed / 20)\n","    risk += 0.1 * (percentage_trees / 100)\n","    return np.clip(risk, 0, 1)\n"],"metadata":{"id":"MoeJV3BynqT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Расчет маски"],"metadata":{"id":"t-FHyNC4nruv"}},{"cell_type":"code","source":["# Создание маски на основе инфрокрасного и rgb изображений\n","def create_mask(green_layer, lst_celsius_normalized, green_border, lst_border):\n","    # Создаем условие для создания маски: зеленый канал должен быть больше green_border,\n","    # а нормализованная температура должна быть больше lst_border\n","    condition = (green_layer > green_border) & (lst_celsius_normalized > lst_border)\n","    # Возвращаем маску, где 1 соответствует условию, а 0 - не соответствует\n","    return np.where(condition, 1, 0)\n","\n","# Нормализация данных для подсчета маски\n","def get_mask(file_path, humidity, wind_speed, unet: UNet):\n","    # Задаем границы для зеленого канала и температуры\n","    green_border = 0.05\n","    lst_border = 0.55\n","\n","    # Создаем объект TiffData для работы с TIFF файлом\n","    tiff_data = TiffData(file_path)\n","\n","    # Посчет коэфицентов необходимых для формулы\n","    # Радиометрическая коррекция инфракрасного канала\n","    radiance = ML * tiff_data.infrared_layer + AL\n","    # Расчет яркостной температуры\n","    brightness_temp = K2 / (np.log((K1 / radiance) + 1))\n","    # Расчет температуры поверхности земли (LST)\n","    lst = brightness_temp / (1 + (lambda_ir * brightness_temp / rho) * np.log(epsilon))\n","\n","    # Расчет оценки пожара с помощью сети UNet\n","    fire_score = calculate_fire_score(unet.predict(tiff_data.image), humidity, wind_speed)\n","\n","    # Нормализация температуры поверхности земли с учетом оценки пожара\n","    lst_normalized = ((lst - lst.min()) / (lst.max() - lst.min())) * (1 + fire_score * 0.01)\n","\n","    # Создаем маску на основе зеленого канала и нормализованной температуры\n","    mask = create_mask(tiff_data.green_layer, lst_normalized, green_border, lst_border) * 255\n","\n","    # Преобразуем маску в изображение\n","    image = Image.fromarray(mask.astype(np.uint8), mode=\"L\")\n","\n","    # Возвращаем маску и исходное RGB изображение\n","    return image, tiff_data.image\n"],"metadata":{"id":"_eHg2W0knrMi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Наложение получившенийся маски и доп данных на исходное изображение"],"metadata":{"id":"P7Vc3kwAyKaR"}},{"cell_type":"code","source":["def color_mask(image, mask, color=(255, 0, 0)):\n","    image = image.convert(\"RGB\")\n","    mask = mask.convert(\"L\")\n","    color_image = Image.new(\"RGB\", image.size, color)\n","    alpha_mask = mask.point(lambda p: p > 128 and 255)  # Преобразуем белые пиксели в альфа-канал\n","    result_image = Image.composite(color_image, image, alpha_mask)\n","    return result_image\n","\n","def draw_wind_arrow(img, wind_speed, wind_direction, arrow_color=(255, 255, 255), text_size=20):\n","    draw = ImageDraw.Draw(img)\n","    width, height = img.size\n","    center_x, center_y = width // 2, height // 2\n","\n","    # Длина стрелки\n","    arrow_length = int(min(width, height) * 0.2)\n","\n","    # Начальная и конечная точка стрелки\n","    start_x = center_x - (arrow_length / 2) * math.cos(math.radians(wind_direction))\n","    start_y = center_y + (arrow_length / 2) * math.sin(math.radians(wind_direction))\n","    end_x = center_x + (arrow_length / 2) * math.cos(math.radians(wind_direction))\n","    end_y = center_y - (arrow_length / 2) * math.sin(math.radians(wind_direction))\n","\n","    # Рисуем линию (тело стрелки)\n","    draw.line((start_x, start_y, end_x, end_y), fill=arrow_color, width=5)\n","\n","    # Величина и угол крыльев стрелки\n","    arrow_head_size = arrow_length * 0.25  # Длина крыльев = 1/4 от длины стрелки\n","    arrow_head_angle = 30  # Угол между крыльями и основным направлением стрелки\n","\n","    # Левое крыло\n","    left_wing_x = end_x - arrow_head_size * math.cos(math.radians(wind_direction + arrow_head_angle))\n","    left_wing_y = end_y + arrow_head_size * math.sin(math.radians(wind_direction + arrow_head_angle))\n","\n","    # Правое крыло\n","    right_wing_x = end_x - arrow_head_size * math.cos(math.radians(wind_direction - arrow_head_angle))\n","    right_wing_y = end_y + arrow_head_size * math.sin(math.radians(wind_direction - arrow_head_angle))\n","\n","    # Рисуем крылья стрелки\n","    draw.polygon([(end_x, end_y), (left_wing_x, left_wing_y), (right_wing_x, right_wing_y)], fill=arrow_color)\n","\n","    # Рисуем текст (скорость ветра)\n","    try:\n","        font = ImageFont.truetype(\"arial.ttf\", text_size)\n","    except IOError:\n","        font = ImageFont.load_default()\n","\n","    text = f\"{wind_speed} m/s\"\n","    text_offset = 25  # Смещение текста от конца стрелки\n","    text_x = end_x + text_offset * math.cos(math.radians(wind_direction))\n","    text_y = end_y - text_offset * math.sin(math.radians(wind_direction))\n","\n","    # Отрисовка текста\n","    draw.text((text_x, text_y), text, fill=arrow_color, font=font)\n","\n","    return img\n"],"metadata":{"id":"W6IL-7VuyFoX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Подсчет метрики на данных"],"metadata":{"id":"GIt4MewZznvb"}},{"cell_type":"code","source":["# Подсчет среднего значения Коэфициента Корреляции Метьюса (далее MCC) для файлов train датасета\n","def get_score(path_to_tiffs='data/merged/',\n","              weather_data_path='weather_data.csv',\n","              path_to_masks='data/masks/'):\n","    # Читаем данные о погоде из CSV файла\n","    weather_data = pd.read_csv(weather_data_path, index_col='file_id')\n","\n","    # Создаем экземпляр сети UNet\n","    unet = UNet()\n","\n","    # Инициализируем переменную для хранения суммы MCC\n","    total_mcc = 0\n","\n","    # Цикл по всем файлам\n","    for i in range(21):\n","        img = Image.open(f'{path_to_masks}/{i:02}.jpg').convert('L')\n","        # Преобразуем маску в numpy массив\n","        mask = np.array(img)\n","        # Бинаризуем маску (0 или 1)\n","        binary_mask = np.where(mask > 128, 1, 0)\n","        wdata = weather_data.loc[i]\n","        # Получаем маску для текущего файла с помощью функции get_mask\n","        mask = get_mask(f'{path_to_tiffs}/{i:02}.tiff',\n","                        wdata['humidity'], wdata['wind_speed'], unet)\n","        # Расчет MCC для текущей маски\n","        mcc = calculate_mcc(binary_mask, mask)\n","        # Масштабируем MCC\n","        scaled_mcc = scale_mcc(mcc)\n","        # Добавляем MCC к сумме\n","        total_mcc += scaled_mcc\n","    return total_mcc / 21\n"],"metadata":{"id":"5GcSH1a-zl3M"},"execution_count":null,"outputs":[]}]}